{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from os import path, environ, makedirs\n",
    "from dotenv import load_dotenv\n",
    "from unidecode import unidecode\n",
    "\n",
    "from core.geo import areal_weighted_interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando os dados extraídos no notebook anterior\n",
    "\n",
    "Neste notebook, vamos utilizar os dados extraídos e salvos pelo notebook `03 habitação - extração.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = path.join('data', 'input', 'urbanismo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join(input_dir, 'orcamento_habitacao_original.csv')\n",
    "df_orcamento = pd.read_csv(filename,\n",
    "            sep=';',\n",
    "            decimal=',',\n",
    "            encoding='utf8',\n",
    "            dtype=str)\n",
    "df_orcamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [col for col in df_orcamento.columns if 'Vl' in col]:\n",
    "    df_orcamento[col] = df_orcamento[col].astype(float)\n",
    "df_orcamento['DataExtracao'] = pd.to_datetime(df_orcamento['DataExtracao'])\n",
    "df_orcamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join(input_dir, 'orcamento_regionalizado_habitacao_original.csv')\n",
    "df_orcamento_r = pd.read_csv(filename,\n",
    "            sep=';',\n",
    "            decimal=',',\n",
    "            encoding='utf8',\n",
    "            dtype=str)\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r['VALOR_DETALHAMENTO_AÇÃO'] = df_orcamento_r['VALOR_DETALHAMENTO_AÇÃO'].astype(float)\n",
    "df_orcamento_r['DATA_EXTRAÇÃO'] = pd.to_datetime(df_orcamento_r['DATA_EXTRAÇÃO'])\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join(input_dir, 'pdm_meta_12_original.csv')\n",
    "df_meta_12 = pd.read_csv(filename,\n",
    "            sep=';',\n",
    "            decimal=',',\n",
    "            encoding='utf8')\n",
    "df_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join(input_dir, 'his_entregue_original.csv')\n",
    "df_his = pd.read_csv(filename,\n",
    "            sep=';',\n",
    "            decimal=',',\n",
    "            encoding='utf8')\n",
    "df_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join(input_dir, 'tpu_emitido_original.csv')\n",
    "df_tpu = pd.read_csv(filename,\n",
    "            sep=';',\n",
    "            decimal=',',\n",
    "            encoding='utf8')\n",
    "df_tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join(input_dir, 'favelas_original.gpkg')\n",
    "df_favelas = gpd.read_file(filename)\n",
    "df_favelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vamos precisar fazer a interseção espacial entre os dados de favelas e o mapa de subprefeituras, vamos carregar também o mapa de subprefeituras, que foi salvo pelo notebook `01 areas de risco - extração.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join(input_dir, 'subprefeituras_original.gpkg')\n",
    "gdf_subs = gpd.read_file(filename)\n",
    "gdf_subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação e padronização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos indicadores de habitação, apenas o ano e as subprefeituras são presentes em vários arquivos. Mas, além disso, os arquivos precisarão de tratamentos específicos. Vamos começar com os mais simples, onde é necessário apenas padronizar as subprefeituras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos carregar os dados de subprefeituras que serão utilizados no Qlik Sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV de Subprefeituras do Qlik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_subs = environ.get('CSV_SUBPREFEITURAS_QLIK')\n",
    "df_subs = pd.read_csv(url_subs)\n",
    "df_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subs = df_subs[['sub.CODIGO', 'sub.NOME']]\n",
    "df_subs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chave composta subprefeitura-ano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como 3 tabelas possuem valores para mais de um ano, também vale a pena a criação de uma chave composta entre subprefeitura e ano. A tabela que possui mais períodos é a tabela da meta 12 do Programa de Metas, com os anos de 2021, 2022, 2023 e 2024. Vamos criar uma tabela com o produto cartesiano entre subprefeituras e anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subs_ano = (\n",
    "    df_subs[['sub.NOME']]\n",
    "    .merge(pd.Series(data=[2021, 2022, 2023, 2024], name='ano'),\n",
    "           how='cross')\n",
    ")\n",
    "\n",
    "df_subs_ano.loc[:, 'subprefeitura-ano'] = (\n",
    "    df_subs_ano.loc[:, 'sub.NOME'] + ' | ' + df_subs_ano.loc[:, 'ano'].astype(str)\n",
    ")\n",
    "\n",
    "df_subs_ano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PdM - Meta 12: Prover 49.000 moradias de interesse social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_12 = df_meta_12.loc[:, ['Subprefeitura', '2021', '2022', '2023', '2024']]\n",
    "\n",
    "df_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_12 = df_meta_12.melt('Subprefeitura',\n",
    "                var_name='ano',\n",
    "                value_name='qtd_unidades_acumulado')\n",
    "\n",
    "df_meta_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os valores foram divulgados no acumulado entre 2021 e 2024, vamos calcular o incremento de cada ano antes de carregar os dados no Qlik, mas mantendo as duas colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_12['qtd_unidades'] = df_meta_12.groupby('Subprefeitura')['qtd_unidades_acumulado'].diff()\n",
    "df_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_12.loc[df_meta_12['ano']=='2021', 'qtd_unidades'] = (\n",
    "    df_meta_12.loc[df_meta_12['ano']=='2021', 'qtd_unidades_acumulado'])\n",
    "df_meta_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, vamos criar uma coluna com os nomes padronizados de subprefeituras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_meta_12 = df_meta_12['Subprefeitura'].apply(unidecode).unique().tolist()\n",
    "subs_meta_12.sort()\n",
    "subs_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_qlik = df_subs['sub.NOME'].unique().tolist()\n",
    "subs_qlik.sort()\n",
    "subs_qlik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subs_meta_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que existem 3 subprefeituras faltantes no dataframe da meta 12. Vamos avaliar quais podem ser. Numa inspeção detalhada vemos que faltam `ARICANDUVA-FORMOSA-CARRAO`, `SAO MIGUEL` e `VILA MARIANA`. Vamos criar uma cópia da lista de subs do qlik adaptada à meta 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_qlik_meta_12 = subs_qlik.copy()\n",
    "subs_qlik_meta_12.remove('ARICANDUVA-FORMOSA-CARRAO')\n",
    "subs_qlik_meta_12.remove('SAO MIGUEL')\n",
    "subs_qlik_meta_12.remove('VILA MARIANA')\n",
    "subs_qlik_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_meta_12 = {\n",
    "    o: q\n",
    "    for o, q in zip(subs_meta_12, subs_qlik_meta_12)\n",
    "}\n",
    "\n",
    "mapper_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_12.insert(1,\n",
    "                  'sub.NOME',\n",
    "                  df_meta_12['Subprefeitura'].apply(unidecode).map(mapper_meta_12))\n",
    "df_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_12['qtd_unidades'] = df_meta_12['qtd_unidades'].astype(int)\n",
    "df_meta_12['qtd_unidades_acumulado'] = df_meta_12['qtd_unidades_acumulado'].astype(int)\n",
    "df_meta_12['ano'] = df_meta_12['ano'].astype(int)\n",
    "df_meta_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta_12 = df_meta_12.merge(df_subs_ano,\n",
    "                              how='left',\n",
    "                              on=['sub.NOME', 'ano'])\n",
    "\n",
    "df_meta_12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produção de habitação de interesse social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_his = df_his['região'].apply(unidecode).unique().tolist()\n",
    "subs_his.sort()\n",
    "subs_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_his = {\n",
    "    s: q for s, q in zip(subs_his, subs_qlik)\n",
    "}\n",
    "\n",
    "mapper_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_his.insert(1,\n",
    "                  'sub.NOME',\n",
    "                  df_his['região'].apply(unidecode).map(mapper_his))\n",
    "df_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_his['qtd_unidades'] = df_his['qtd_unidades'].astype(int)\n",
    "df_his['ano'] = df_his['ano'].astype(int)\n",
    "df_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_his = df_his.merge(df_subs_ano,\n",
    "                              how='left',\n",
    "                              on=['sub.NOME', 'ano'])\n",
    "\n",
    "df_his"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número de termos de Permissão de Uso (TPU) emitidos em nome da mulher da familia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tpu['qtd_termos'] = df_tpu['qtd_termos'].astype(int)\n",
    "df_tpu['ano'] = df_tpu['ano'].astype(int)\n",
    "df_tpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Número de domicílios em favelas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como os domicílios em favelas não possuem uma coluna identificando a subprefeitura, precisamos fazer a interseção espacial entre os dados de favelas e o mapa de subprefeituras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos chegar se existem favelas que estão dentro de mais de uma subprefeitura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fav_sub = df_favelas.overlay(gdf_subs, how='intersection')\n",
    "df_fav_sub.iloc[:,0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem 8 registros duplicados, o que indica que algumas favelas estão em mais de uma subprefeitura. Portanto, um spatial join simples não funcionará. Vamos fazer a interseção espacial entre os dois dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolação ponderada por área"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fav_sub = areal_weighted_interpolation(\n",
    "    left=df_favelas,\n",
    "    right=gdf_subs,\n",
    "    right_id_col='nm_subprefeitura',\n",
    "    original_var_name='Particular permanente',\n",
    "    final_var_name='domicilios_particulares_permanentes_favela'\n",
    ")\n",
    "df_fav_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas['Particular permanente'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fav_sub['domicilios_particulares_permanentes_favela'].sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas['Particular permanente'].sum()-df_fav_sub['domicilios_particulares_permanentes_favela'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-df_fav_sub['domicilios_particulares_permanentes_favela'].sum()/df_favelas['Particular permanente'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cerca de 659 domicílios em favelas não foram alocados a nenhuma subprefeitura. Isso representa apenas 0,1% do total de domicílios em favelas, então não é uma perda grave. Porém, o caso mais provável é de que parte dessas favelas estejam fora do limite das subprefeituras, o que não deveria ocorrer com os dados de favelas filtrados apenas para o município de São Paulo. Vamos investigar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando domicílios não alocados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora = df_favelas.overlay(gdf_subs, how='difference', keep_geom_type=True)\n",
    "df_favelas_fora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como era esperado, existem favelas que estão parcialmente fora do limite do município de São Paulo. Vamos inspecionar visualmente onde estão essas favelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gdf_subs.explore(\n",
    "    tiles='CartoDB positron',\n",
    "    tooltip=True,\n",
    "    popup=True,\n",
    "    style_kwds=dict(color='grey', fill=False))\n",
    "\n",
    "m = df_favelas_fora.explore(\n",
    "    m=m,\n",
    "    legend=True,\n",
    "    tooltip=True,\n",
    "    popup=True)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato, existem favelas que estão parcialmente fora do limite do município de São Paulo, e são onde existem as áreas mais significativas de favelas fora das subprefeituras. Porém, também existem casos áreas de favelas que estão completamente dentro do município de São Paulo, mas que não foram alocadas a nenhuma subprefeitura por se situarem exatamente na divisa entre subprefeituras, mas provavelmente isso não representa uma área grande o suficiente para distorcer as estimativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificando áreas fora dos limites das subprefeituras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De todo modo, vamos calcular a proporção de domicílios dessas áreas que não foram alocados a nenhuma subprefeitura, e aplicar essa proporção para redistribuir os domicílios não alocados entre as subprefeituras. Com a proporção de domicílios calculada, podemos atribuir os domicílios não alocados à subprefeitura mais próxima de cada área de favela não alocada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora['area_total'] = df_favelas_fora.apply(\n",
    "    lambda row: df_favelas.query(f'cd_fcu==\"{row.cd_fcu}\"').geometry.area.iloc[0],\n",
    "    axis=1)\n",
    "\n",
    "df_favelas_fora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora['area_fora'] = df_favelas_fora.geometry.area\n",
    "df_favelas_fora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora['peso'] = (\n",
    "    df_favelas_fora['area_fora'] / df_favelas_fora['area_total']\n",
    ")\n",
    "df_favelas_fora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora['domicilios_favela_fora'] = (\n",
    "    df_favelas_fora['peso'] * df_favelas_fora['Particular permanente']\n",
    ").round().astype(int)\n",
    "df_favelas_fora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora['domicilios_favela_fora'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De fato, 655 dos 659 domicílios não alocados estão em favelas que estão parcialmente fora do limite do município de São Paulo. Os outros 4 domicílios provavelmente são falhas de arredondamento. Antes de atribuir os domicílios não alocados, às subprefeituras mais próximas, vamos excluir do dataframe as áreas sem domicílios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora = df_favelas_fora[df_favelas_fora['domicilios_favela_fora']>0]\n",
    "df_favelas_fora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atribuindo domicílios não alocados às subprefeituras mais próximas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora = df_favelas_fora.sjoin_nearest(\n",
    "    gdf_subs[['nm_subprefeitura', 'geometry']],\n",
    "    how='left'\n",
    ").drop(columns='index_right')\n",
    "\n",
    "df_favelas_fora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como algumas áreas de favelas estão em mais de uma subprefeitura, precisamos remover uma das duplicatas. Vamos manter a primeira ocorrência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas_fora = df_favelas_fora.drop_duplicates(subset=['cd_fcu']).reset_index(drop=True)\n",
    "\n",
    "df_favelas_fora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, podemos agregar o número de domicílios em favelas por subprefeitura e adicionar ao dataframe anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fav_sub_fora = (\n",
    "    df_favelas_fora\n",
    "    .groupby('nm_subprefeitura', as_index=False)\n",
    "    .agg(\n",
    "        domicilios_favela_fora = ('domicilios_favela_fora', 'sum')\n",
    "    )\n",
    ")\n",
    "\n",
    "df_fav_sub_fora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregando os domicílios em favelas por subprefeitura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_fora = df_fav_sub['nm_subprefeitura'].isin(df_fav_sub_fora['nm_subprefeitura'])\n",
    "\n",
    "df_fav_sub.loc[subs_fora, 'domicilios_particulares_permanentes_favela'] = (\n",
    "    df_fav_sub\n",
    "    .loc[subs_fora]\n",
    "    .apply(lambda row: row['domicilios_particulares_permanentes_favela']\n",
    "           + df_fav_sub_fora.loc[df_fav_sub_fora['nm_subprefeitura']==row['nm_subprefeitura'], 'domicilios_favela_fora'].values[0], axis=1)\n",
    ")\n",
    "\n",
    "df_fav_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fav_sub['domicilios_particulares_permanentes_favela'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas['Particular permanente'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favelas['Particular permanente'].sum()-df_fav_sub['domicilios_particulares_permanentes_favela'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-df_fav_sub['domicilios_particulares_permanentes_favela'].sum()/df_favelas['Particular permanente'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim, temos uma perda de apenas 4 domicílios em favelas, dentro do universo de 649.765 domicílios em favelas, o que representa uma perda de apenas 0,0006%. Ademais, essa perda provavelmente se deve a falhas de arredondamento, então podemos considerar que a estimativa está satisfatória."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronizando os nomes de subprefeituras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_favelas = df_fav_sub['nm_subprefeitura'].apply(unidecode).unique().tolist()\n",
    "subs_favelas.sort()\n",
    "subs_favelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subs_favelas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tamanho da lista de subs indica que uma das subprefeituras não possui nenhum domicílio em favelas. Inspecionando a lista, vemos que a subprefeitura faltante é a de Pinheiros, o que parece fazer sentido. Primeiro, vamos criar uma cópia da lista de subs do qlik adaptada aos dados de domicílios em favelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_qlik_favelas = subs_qlik.copy()\n",
    "subs_qlik_favelas.remove('PINHEIROS')\n",
    "subs_qlik_favelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_favelas = {\n",
    "    s: q for s, q in zip(subs_favelas, subs_qlik_favelas)\n",
    "}\n",
    "\n",
    "mapper_favelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(s != q for s, q in mapper_favelas.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recriando com base no df_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fav_sub_final = (\n",
    "    df_subs\n",
    "    .merge(df_fav_sub[['nm_subprefeitura',\n",
    "                          'sg_subprefeitura',\n",
    "                          'domicilios_particulares_permanentes_favela']],\n",
    "                how='left',\n",
    "                left_on='sub.NOME',\n",
    "                right_on='nm_subprefeitura')\n",
    "    .drop(columns=['nm_subprefeitura'])\n",
    ")\n",
    "\n",
    "df_fav_sub_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, completamos os campos vazios da subprefeitura de Pinheiros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fav_sub_final['domicilios_particulares_permanentes_favela'] = (\n",
    "    df_fav_sub_final['domicilios_particulares_permanentes_favela']\n",
    "    .fillna(0)\n",
    "    .astype(int)\n",
    ")\n",
    "\n",
    "df_fav_sub_final.loc[df_fav_sub_final['sub.NOME']=='PINHEIROS', 'sg_subprefeitura'] = (\n",
    "    gdf_subs.loc[gdf_subs['nm_subprefeitura']=='PINHEIROS', 'sg_subprefeitura'].values[0]\n",
    ")\n",
    "\n",
    "df_fav_sub_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orçamento do Programa de habitação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o orçamento, além de padronizar os nomes de subprefeituras e tipos de dados das métricas, precisaremos também adaptar os dados para compatibilizar o orçamento regionalizado e não realizado. Para isso, vamos fazer o seguinte:\n",
    "\n",
    "1. Classificar o orçamento detalhado por nível de regionalização nas seguintes categorias: subprefeitura, região e não regionalizável;\n",
    "1. Agrupar o restante do orçamento não detalhado e manter apenas o orçamento inicial, atualizado e liquidado;\n",
    "1. Subtrair o total do orçamento detalhado do orçamento não detalhado e classificar o nível de regionalização como não regionalizado;\n",
    "1. Unir os dois dataframes de orçamento de acordo com as dimensões mantidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orçamento regionalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_orcamento_r = ['CÓDIGO_ÓRGÃO', 'SIGLA_ÓRGÃO', 'DESCRIÇÃO_ÓRGÃO',\n",
    "                    'CÓDIGO_PROGRAMA', 'DESCRIÇÃO_PROGRAMA',\n",
    "                    'CÓDIGO_PROJ_ATIV', 'DESCRIÇÃO_PROJ_ATIV',\n",
    "                    'CÓDIGO_VÍNCULO_PMSP', 'REGIÃO',\n",
    "                    'SUBPREFEITURA', 'TIPO_REGIONALIZAÇÃO']\n",
    "\n",
    "cols_orcamento_r_vl = ['VALOR_DETALHAMENTO_AÇÃO']\n",
    "\n",
    "df_orcamento_r = df_orcamento_r[cols_orcamento_r + cols_orcamento_r_vl]\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r['TIPO_REGIONALIZAÇÃO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r.loc[df_orcamento_r['TIPO_REGIONALIZAÇÃO'].isna(), 'TIPO_REGIONALIZAÇÃO'] = 'Despesa Não-Regionalizável'\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r['TIPO_REGIONALIZAÇÃO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r = df_orcamento_r.groupby(cols_orcamento_r).sum().round(2).reset_index()\n",
    "\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r.loc[\n",
    "    ~df_orcamento_r['REGIÃO'].str.contains('Supra', na=False),\n",
    "    'NIVEL_REGIONALIZAÇÃO'] = 'Região'\n",
    "\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r.loc[\n",
    "    ~df_orcamento_r['SUBPREFEITURA'].str.contains('Supra', na=False),\n",
    "    'NIVEL_REGIONALIZAÇÃO'] = 'Subprefeitura'\n",
    "\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r.loc[df_orcamento_r['NIVEL_REGIONALIZAÇÃO'].isna(), 'NIVEL_REGIONALIZAÇÃO'] = 'Não regionalizável'\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orçamento não regionalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_orcamento = ['Cd_Orgao', 'Sigla_Orgao', 'Ds_Orgao', 'Cd_Programa',\n",
    "                  'Ds_Programa', 'ProjetoAtividade', 'Ds_Projeto_Atividade',\n",
    "                  'COD_VINC_REC_PMSP']\n",
    "\n",
    "cols_orcamento_vl = ['Vl_Orcado_Ano', 'Vl_Orcado_Atualizado', 'Vl_Liquidado']\n",
    "\n",
    "df_orcamento_original = df_orcamento.copy()\n",
    "df_orcamento = df_orcamento[cols_orcamento + cols_orcamento_vl]\n",
    "df_orcamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento = df_orcamento.groupby(cols_orcamento).sum().reset_index()\n",
    "df_orcamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_agg_cols = ['CÓDIGO_ÓRGÃO', 'CÓDIGO_PROGRAMA', 'CÓDIGO_PROJ_ATIV',\n",
    "              'CÓDIGO_VÍNCULO_PMSP']\n",
    "\n",
    "agg_cols = ['Cd_Orgao', 'Cd_Programa', 'ProjetoAtividade',\n",
    "            'COD_VINC_REC_PMSP']\n",
    "\n",
    "df_orcamento_r_agg = (\n",
    "    df_orcamento_r[r_agg_cols + ['VALOR_DETALHAMENTO_AÇÃO']]\n",
    "    .groupby(r_agg_cols)\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_orcamento_r_agg.loc[:, 'VALOR_DETALHAMENTO_AÇÃO'] = (\n",
    "    df_orcamento_r_agg\n",
    "    .loc[:, 'VALOR_DETALHAMENTO_AÇÃO']\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "df_orcamento_ajustado = df_orcamento.merge(\n",
    "    df_orcamento_r_agg,\n",
    "    left_on=agg_cols,\n",
    "    right_on=r_agg_cols,\n",
    "    how='left'\n",
    ").drop(columns=r_agg_cols)\n",
    "\n",
    "df_orcamento_ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_ajustado.loc[df_orcamento_ajustado['VALOR_DETALHAMENTO_AÇÃO'].isna(), 'VALOR_DETALHAMENTO_AÇÃO'] = 0\n",
    "\n",
    "df_orcamento_ajustado.loc[:, 'Vl_Liquidado_N_Detalhado'] = (\n",
    "    df_orcamento_ajustado.loc[:, 'Vl_Liquidado']\n",
    "    - df_orcamento_ajustado.loc[:, 'VALOR_DETALHAMENTO_AÇÃO']).round(2)\n",
    "\n",
    "df_orcamento_ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_ajustado[df_orcamento_ajustado['Vl_Liquidado_N_Detalhado']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_ajustado[['Vl_Liquidado', 'VALOR_DETALHAMENTO_AÇÃO']].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unindo os dados de orçamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos adicionar os dados não detalhados ao dataframe que contém o orçamento detalhado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orcamento_cols_map = {'Cd_Orgao': 'CÓDIGO_ÓRGÃO',\n",
    "                      'Sigla_Orgao': 'SIGLA_ÓRGÃO',\n",
    "                      'Ds_Orgao': 'DESCRIÇÃO_ÓRGÃO',\n",
    "                      'Cd_Programa': 'CÓDIGO_PROGRAMA',\n",
    "                      'Ds_Programa': 'DESCRIÇÃO_PROGRAMA',\n",
    "                      'ProjetoAtividade': 'CÓDIGO_PROJ_ATIV',\n",
    "                      'Ds_Projeto_Atividade': 'DESCRIÇÃO_PROJ_ATIV',\n",
    "                      'COD_VINC_REC_PMSP': 'CÓDIGO_VÍNCULO_PMSP',\n",
    "                      'Vl_Liquidado_N_Detalhado': 'Vl_Liquidado'}\n",
    "\n",
    "df_orcamento_ajustado = (\n",
    "    df_orcamento_ajustado\n",
    "    .drop(columns=['VALOR_DETALHAMENTO_AÇÃO', 'Vl_Liquidado'])\n",
    "    .rename(columns=orcamento_cols_map)\n",
    "    )\n",
    "\n",
    "df_orcamento_ajustado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_r = (df_orcamento_r\n",
    "                  .rename(columns={'VALOR_DETALHAMENTO_AÇÃO': 'Vl_Liquidado'}))\n",
    "\n",
    "df_orcamento_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_final = pd.concat([df_orcamento_r, df_orcamento_ajustado])\n",
    "\n",
    "df_orcamento_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_final.loc[df_orcamento_final['Vl_Orcado_Ano'].isna(),\n",
    "                       'Vl_Orcado_Ano'] = 0\n",
    "df_orcamento_final.loc[df_orcamento_final['Vl_Orcado_Atualizado'].isna(),\n",
    "                       'Vl_Orcado_Atualizado'] = 0\n",
    "df_orcamento_final.loc[df_orcamento_final['NIVEL_REGIONALIZAÇÃO'].isna(),\n",
    "                       'NIVEL_REGIONALIZAÇÃO'] = 'Não detalhado'\n",
    "\n",
    "df_orcamento_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padronizando os nomes de subprefeituras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_orcamento = (\n",
    "    df_orcamento_final.loc[~df_orcamento_final['SUBPREFEITURA'].isna(), 'SUBPREFEITURA']\n",
    "    .apply(unidecode)\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "subs_orcamento.sort()\n",
    "\n",
    "subs_orcamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_orcamento[:-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(subs_orcamento[:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs_qlik_orcamento = subs_qlik.copy()\n",
    "# As 3 subs abaixo não aparecem na lista de liquidação do orçamento\n",
    "subs_qlik_orcamento.remove('ERMELINO MATARAZZO')\n",
    "subs_qlik_orcamento.remove('PIRITUBA-JARAGUA')\n",
    "subs_qlik_orcamento.remove('VILA MARIANA')\n",
    "# Guainases e Vila Prudente aparecem em uma ordenação diferente, por isso serão\n",
    "# removidas e adicionadas novamente ao final da lista\n",
    "subs_qlik_orcamento.remove('GUAIANASES')\n",
    "subs_qlik_orcamento.remove('VILA PRUDENTE')\n",
    "subs_qlik_orcamento.append('GUAIANASES')\n",
    "subs_qlik_orcamento.append('VILA PRUDENTE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_orcamento = {\n",
    "    so: sq\n",
    "    for so, sq in zip(subs_orcamento, subs_qlik_orcamento)\n",
    "}\n",
    "\n",
    "mapper_orcamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_final.insert(\n",
    "    7,\n",
    "    'sub.NOME',\n",
    "    df_orcamento_final.loc[:,'SUBPREFEITURA'].apply(lambda s: unidecode(s) if isinstance(s, str) else None).map(mapper_orcamento)\n",
    ")\n",
    "\n",
    "df_orcamento_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_final.loc[:, 'ano'] = 2024\n",
    "\n",
    "# df_orcamento_final = df_orcamento_final.merge(df_subs_ano,\n",
    "#                               how='left',\n",
    "#                               on=['sub.NOME', 'ano'])\n",
    "\n",
    "df_orcamento_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando as subprefeituras faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orcamento_subs_cols = ['CÓDIGO_ÓRGÃO', 'SIGLA_ÓRGÃO', 'DESCRIÇÃO_ÓRGÃO',\n",
    "                       'CÓDIGO_PROGRAMA', 'DESCRIÇÃO_PROGRAMA',\n",
    "                       'CÓDIGO_PROJ_ATIV', 'DESCRIÇÃO_PROJ_ATIV',\n",
    "                       'CÓDIGO_VÍNCULO_PMSP', 'ano']\n",
    "\n",
    "df_orcamento_subs = df_orcamento_final[orcamento_subs_cols].copy()\n",
    "df_orcamento_subs = df_orcamento_subs.drop_duplicates().reset_index(drop=True)\n",
    "df_orcamento_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_subs['TIPO_REGIONALIZAÇÃO'] = 'Despesa Regionalizável'\n",
    "df_orcamento_subs['NIVEL_REGIONALIZAÇÃO'] = 'Subprefeitura'\n",
    "\n",
    "df_orcamento_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_subs = (\n",
    "    df_orcamento_subs\n",
    "    .merge(pd.DataFrame(columns=['sub.NOME'], data=subs_qlik),\n",
    "           how='cross')\n",
    ")\n",
    "\n",
    "df_orcamento_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_completo = (\n",
    "    df_orcamento_final\n",
    "    .merge(df_orcamento_subs,\n",
    "           how='outer',\n",
    "           on=df_orcamento_subs.columns.tolist())\n",
    ")\n",
    "\n",
    "df_orcamento_completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_completo.loc[df_orcamento_completo['Vl_Liquidado'].isna(), 'Vl_Liquidado'] = 0\n",
    "df_orcamento_completo.loc[df_orcamento_completo['Vl_Orcado_Ano'].isna(), 'Vl_Orcado_Ano'] = 0\n",
    "df_orcamento_completo.loc[df_orcamento_completo['Vl_Orcado_Atualizado'].isna(), 'Vl_Orcado_Atualizado'] = 0\n",
    "\n",
    "df_orcamento_completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando descrição das vinculações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_completo = (\n",
    "    df_orcamento_completo\n",
    "    .merge(df_orcamento_original[['COD_VINC_REC_PMSP', 'TXT_VINC_PMSP']].drop_duplicates(),\n",
    "            how='left',\n",
    "            left_on='CÓDIGO_VÍNCULO_PMSP',\n",
    "            right_on='COD_VINC_REC_PMSP')\n",
    "    .drop(columns='COD_VINC_REC_PMSP')\n",
    ")\n",
    "\n",
    "df_orcamento_completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando a chave composta subprefeitura-ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orcamento_completo = df_orcamento_completo.merge(df_subs_ano,\n",
    "                                                    how='left',\n",
    "                                                    left_on=['sub.NOME', 'ano'],\n",
    "                                                    right_on=['sub.NOME', 'ano'])\n",
    "\n",
    "df_orcamento_completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Armazenamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, vamos exportar os dados em formato csv compatível com o Qlik e no padrão do excel para português do Brasil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = path.join('data_output', 'urbanismo')\n",
    "\n",
    "if not path.exists(base_path):\n",
    "    makedirs(base_path)\n",
    "\n",
    "for name, df in [('orcamento-habitacao', df_orcamento_final),\n",
    "                 ('producao-his', df_his),\n",
    "                 ('pdm-meta-12', df_meta_12),\n",
    "                 ('emissoes-tpu', df_tpu),\n",
    "                 ('subprefeitura-ano', df_subs_ano),\n",
    "                 ('domicilios-favela', df_fav_sub_final),]:\n",
    "\n",
    "    filepath = path.join(base_path, f'{name}.csv')\n",
    "\n",
    "    df.to_csv(filepath,\n",
    "              index=False,\n",
    "              sep=';',\n",
    "              decimal=',',\n",
    "              encoding='latin1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dados-painel-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
